{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Chạy cell này đầu tiên để cài đặt các thư viện cần thiết.\n",
        "!pip install pandas nltk scikit-learn gensim openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHEYxB3rEVZp",
        "outputId": "315814f7-a038-46d3-eac4-32c3fd9e395c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.101.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 2: IMPORT THƯ VIỆN VÀ NẠP DỮ LIỆU\n",
        "# ===================================================================\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import itertools\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "\n",
        "# Tải tài nguyên cần thiết cho VADER\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Tải dữ liệu \"vàng\" đã được xử lý và gộp từ nguồn UCSD\n",
        "# Đây là file output từ notebook tích hợp dữ liệu của bạn.\n",
        "try:\n",
        "    df = pd.read_csv('ucsd_delaware_reviews_combined.csv')\n",
        "    print(\"Tải dữ liệu nâng cấp thành công!\")\n",
        "    print(f\"Tổng số review để xử lý: {len(df)}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Lỗi: Không tìm thấy file 'ucsd_delaware_reviews_combined.csv'.\")\n",
        "    print(\"Hãy chắc chắn bạn đã chạy notebook tích hợp dữ liệu và file này tồn tại.\")\n",
        "\n",
        "# Hiển thị thông tin cơ bản để kiểm tra\n",
        "if 'df' in locals():\n",
        "    print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmCzv_BBEXew",
        "outputId": "01f5b446-5b3f-42b7-d91c-6162bb445d0a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tải dữ liệu nâng cấp thành công!\n",
            "Tổng số review để xử lý: 58289\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 58289 entries, 0 to 58288\n",
            "Data columns (total 13 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   gmap_id         58289 non-null  object \n",
            " 1   user_id         58289 non-null  object \n",
            " 2   user_name       58289 non-null  object \n",
            " 3   time            58289 non-null  int64  \n",
            " 4   rating          58289 non-null  int64  \n",
            " 5   text            58288 non-null  object \n",
            " 6   text_clean      58209 non-null  object \n",
            " 7   place_name      58289 non-null  object \n",
            " 8   address         58109 non-null  object \n",
            " 9   category        58288 non-null  object \n",
            " 10  avg_rating      58289 non-null  float64\n",
            " 11  num_of_reviews  58289 non-null  int64  \n",
            " 12  price           23279 non-null  object \n",
            "dtypes: float64(1), int64(3), object(9)\n",
            "memory usage: 5.8+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3: FEATURE ENGINEERING - CÁC ĐẶC TRƯNG CƠ BẢN\n",
        "# ===================================================================\n",
        "print(\"Bắt đầu tạo các đặc trưng cơ bản...\")\n",
        "\n",
        "# 1. Tính toán điểm sentiment\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "df.dropna(subset=['text'], inplace=True) # Đảm bảo không có text rỗng\n",
        "df['sentiment_score'] = df['text'].apply(lambda text: analyzer.polarity_scores(str(text))['compound'])\n",
        "\n",
        "# 2. Đặc trưng Metadata\n",
        "df['review_length'] = df['text'].str.len()\n",
        "df['user_review_count'] = df.groupby('user_id')['user_id'].transform('count')\n",
        "df['rating_deviation'] = (df['rating'] - df['avg_rating']).fillna(0)\n",
        "\n",
        "# 3. Suy luận Tín hiệu \"Đã ghé thăm\"\n",
        "visit_keywords = [\n",
        "    'visited', 'went to', 'ate here', 'dined here', 'was there',\n",
        "    'stayed at', 'my visit', 'our visit', 'ordered', 'tried the'\n",
        "]\n",
        "df['has_visit_keyword'] = df['text'].str.contains('|'.join(visit_keywords), case=False, na=False)\n",
        "\n",
        "print(\"Hoàn thành tạo các đặc trưng cơ bản.\")\n",
        "print(df[['user_name', 'sentiment_score', 'review_length', 'user_review_count', 'has_visit_keyword']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsl3ckTNEeHS",
        "outputId": "6ebcca41-93ee-4e50-b082-2815c6b8ea08"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bắt đầu tạo các đặc trưng cơ bản...\n",
            "Hoàn thành tạo các đặc trưng cơ bản.\n",
            "        user_name  sentiment_score  review_length  user_review_count  \\\n",
            "0  Heather Carper           0.8176            112                  4   \n",
            "1  Heather Carper           0.8176            112                  4   \n",
            "2  STACY CLAVETTE           0.9685            283                  5   \n",
            "3  STACY CLAVETTE           0.9685            283                  5   \n",
            "4       Zion Hood           0.7269             74                  5   \n",
            "\n",
            "   has_visit_keyword  \n",
            "0              False  \n",
            "1              False  \n",
            "2              False  \n",
            "3              False  \n",
            "4              False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4: FEATURE ENGINEERING - NLP NÂNG CAO (TF-IDF & LDA)\n",
        "# ===================================================================\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "\n",
        "print(\"Bắt đầu các bước NLP nâng cao (có thể mất vài phút)...\")\n",
        "\n",
        "# --- a. Keyword Extraction (TF-IDF) ---\n",
        "df['text_clean'] = df['text_clean'].fillna('')\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=2000, stop_words='english')\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df['text_clean'])\n",
        "feature_names = np.array(tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "def extract_top_keywords(doc, top_n=5):\n",
        "    tfidf_vector = tfidf_vectorizer.transform([doc])\n",
        "    sorted_indices = np.argsort(tfidf_vector.toarray()).flatten()[::-1]\n",
        "    top_keywords = feature_names[sorted_indices[:top_n]]\n",
        "    return ', '.join(top_keywords)\n",
        "\n",
        "df['keywords'] = df['text_clean'].apply(extract_top_keywords)\n",
        "print(\"-> Hoàn thành trích xuất từ khóa (Keywords).\")\n",
        "\n",
        "# --- b. Topic Modeling (LDA) ---\n",
        "tokenized_data = [text.split() for text in df['text_clean']]\n",
        "dictionary = corpora.Dictionary(tokenized_data)\n",
        "dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
        "corpus = [dictionary.doc2bow(text) for text in tokenized_data]\n",
        "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, passes=10, random_state=42)\n",
        "\n",
        "print(\"\\nCác chủ đề được phát hiện bởi LDA:\")\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print(f'Topic {idx}: {topic}')\n",
        "\n",
        "def get_dominant_topic(doc):\n",
        "    bow = dictionary.doc2bow(doc.split())\n",
        "    topics = lda_model.get_document_topics(bow, minimum_probability=0.0)\n",
        "    dominant_topic = sorted(topics, key=lambda x: x[1], reverse=True)[0][0]\n",
        "    return dominant_topic\n",
        "\n",
        "df['topic'] = df['text_clean'].apply(get_dominant_topic)\n",
        "print(\"\\n-> Hoàn thành gán chủ đề (Topics).\")\n",
        "print(df[['text', 'keywords', 'topic']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlnGGXKXEgkH",
        "outputId": "dfdce93c-34f2-4da4-8ccb-14fb56b1bc1f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bắt đầu các bước NLP nâng cao (có thể mất vài phút)...\n",
            "-> Hoàn thành trích xuất từ khóa (Keywords).\n",
            "\n",
            "Các chủ đề được phát hiện bởi LDA:\n",
            "Topic 0: 0.048*\"the\" + 0.035*\"to\" + 0.024*\"you\" + 0.023*\"i\" + 0.023*\"they\" + 0.023*\"and\" + 0.023*\"a\" + 0.019*\"is\" + 0.018*\"have\" + 0.014*\"of\"\n",
            "Topic 1: 0.051*\"a\" + 0.034*\"to\" + 0.031*\"of\" + 0.031*\"place\" + 0.030*\"great\" + 0.029*\"for\" + 0.025*\"and\" + 0.025*\"nice\" + 0.016*\"good\" + 0.013*\"very\"\n",
            "Topic 2: 0.093*\"the\" + 0.039*\"and\" + 0.032*\"was\" + 0.029*\"food\" + 0.024*\"is\" + 0.021*\"it\" + 0.019*\"best\" + 0.017*\"good\" + 0.015*\"love\" + 0.014*\"a\"\n",
            "Topic 3: 0.097*\"and\" + 0.090*\"great\" + 0.061*\"very\" + 0.055*\"service\" + 0.044*\"friendly\" + 0.043*\"staff\" + 0.042*\"good\" + 0.026*\"food\" + 0.021*\"helpful\" + 0.021*\"always\"\n",
            "Topic 4: 0.046*\"i\" + 0.041*\"and\" + 0.038*\"the\" + 0.037*\"was\" + 0.033*\"to\" + 0.029*\"my\" + 0.025*\"a\" + 0.016*\"me\" + 0.016*\"for\" + 0.014*\"it\"\n",
            "\n",
            "-> Hoàn thành gán chủ đề (Topics).\n",
            "                                                text  \\\n",
            "0  Lived here for 3 years and enjoyed it. Locatio...   \n",
            "1  Lived here for 3 years and enjoyed it. Locatio...   \n",
            "2  Nice complex and awesome staff.  Maintenance i...   \n",
            "3  Nice complex and awesome staff.  Maintenance i...   \n",
            "4  Good places for people to live my friend lives...   \n",
            "\n",
            "                                           keywords  topic  \n",
            "0    convenience, views, apartments, lived, enjoyed      0  \n",
            "1    convenience, views, apartments, lived, enjoyed      0  \n",
            "2  close, complex, apartments, maintenance, located      0  \n",
            "3  close, complex, apartments, maintenance, located      0  \n",
            "4                 awsome, lives, says, friend, live      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 5: FEATURE ENGINEERING - ĐẶC TRƯNG THỜI GIAN\n",
        "# ===================================================================\n",
        "print(\"Bắt đầu tạo đặc trưng thời gian...\")\n",
        "df['datetime'] = pd.to_datetime(df['time'], unit='ms')\n",
        "df = df.sort_values(by=['user_id', 'datetime'])\n",
        "df['time_delta_seconds'] = df.groupby('user_id')['datetime'].diff().dt.total_seconds().fillna(0)\n",
        "print(\"-> Hoàn thành tính chênh lệch thời gian (Timestamp Delta).\")\n",
        "print(df[['user_name', 'datetime', 'time_delta_seconds']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaZH-ijsEjhc",
        "outputId": "9c4044ac-e75e-4647-9d23-60e857541e00"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bắt đầu tạo đặc trưng thời gian...\n",
            "-> Hoàn thành tính chênh lệch thời gian (Timestamp Delta).\n",
            "          user_name                datetime  time_delta_seconds\n",
            "648     Ronald Keys 2018-03-01 15:56:48.891        0.000000e+00\n",
            "44104  Don Kelleher 2020-05-21 21:43:37.803        0.000000e+00\n",
            "14627   Tom Carroll 2020-02-08 01:04:21.369        0.000000e+00\n",
            "23922   Tom Carroll 2020-10-11 14:24:50.518        2.130243e+07\n",
            "35287  Jeff Peacock 2017-07-23 02:04:50.769        0.000000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 6: MODULE CHÍNH SÁCH - PHÁT HIỆN QUẢNG CÁO VÀ TẠO NHÃN ĐA TRỊ\n",
        "# ===================================================================\n",
        "print(\"Bắt đầu xây dựng Module Chính sách...\")\n",
        "\n",
        "# 1. Thêm dữ liệu giả để kiểm tra logic phát hiện URL\n",
        "promo_text_1 = \"Great place! visit www.mypromo.com for a 10% discount!\"\n",
        "df.loc[len(df)] = df.iloc[0]\n",
        "df.loc[df.index[-1], 'text'] = promo_text_1\n",
        "\n",
        "# 2. Logic phát hiện URL\n",
        "url_pattern = r'(https|http|www)[^\\s]+'\n",
        "df['has_url'] = df['text'].str.contains(url_pattern, case=False, na=False)\n",
        "print(f\"-> Đã tìm thấy {df['has_url'].sum()} review chứa URL.\")\n",
        "\n",
        "# 3. Hàm tạo nhãn đa trị (multi-label) dựa trên luật\n",
        "def create_multilabels(row):\n",
        "    labels = []\n",
        "    if row['sentiment_score'] < -0.5 and not row['has_visit_keyword']:\n",
        "        labels.append('rant_no_visit')\n",
        "    if row['has_url']:\n",
        "        labels.append('ad')\n",
        "    # Giả sử sau khi xem LDA, bạn thấy topic 1 là không liên quan (ví dụ)\n",
        "    # Bạn cần tự điều chỉnh chỉ số topic này sau khi xem kết quả ở cell trên\n",
        "    if row['topic'] == 1:\n",
        "        labels.append('irrelevant')\n",
        "    if not labels:\n",
        "        labels.append('clean')\n",
        "    return labels\n",
        "\n",
        "df['multilabels'] = df.apply(create_multilabels, axis=1)\n",
        "print(\"-> Hoàn thành tạo nhãn đa trị (multi-label) dựa trên luật.\")\n",
        "print(\"\\nKiểm tra review quảng cáo giả vừa thêm:\")\n",
        "print(df[df['has_url']][['text', 'multilabels']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r_ituS3El6Z",
        "outputId": "337f27c3-3827-40bf-8bf3-dfa2d1825d51"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bắt đầu xây dựng Module Chính sách...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1169806186.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  df['has_url'] = df['text'].str.contains(url_pattern, case=False, na=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-> Đã tìm thấy 7 review chứa URL.\n",
            "-> Hoàn thành tạo nhãn đa trị (multi-label) dựa trên luật.\n",
            "\n",
            "Kiểm tra review quảng cáo giả vừa thêm:\n",
            "                                                    text          multilabels\n",
            "9783   Incredibly delicious!!\\nAs always.\\nLuv the su...                 [ad]\n",
            "31808  Very disorganized staff unfriendly and unhelpf...  [rant_no_visit, ad]\n",
            "27067  I live by this place. I don't eat Chinese but ...                 [ad]\n",
            "23844  (Translated by Google) Awwweeeessssooooomeeee ...     [ad, irrelevant]\n",
            "52771  (Translated by Google) Slowwwww at the pharmac...     [ad, irrelevant]\n",
            "37895  Time well spent and well worth it.\\nEvery wher...                 [ad]\n",
            "36516  Great place! visit www.mypromo.com for a 10% d...                 [ad]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 7: MODEL DEVELOPMENT - KẾ HOẠCH A: THỬ VỚI OPENAI API (ĐÃ SỬA LỖI)\n",
        "# ===================================================================\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "import json\n",
        "import time\n",
        "\n",
        "print(\"Bắt đầu Kế hoạch A: Thử nghiệm với OpenAI API...\")\n",
        "\n",
        "# 1. Khởi tạo Client\n",
        "try:\n",
        "    api_key = userdata.get('OPENAI_API_KEY')\n",
        "    client = openai.OpenAI(api_key=api_key)\n",
        "    print(\"-> Đã kết nối với API của OpenAI thành công!\")\n",
        "    openai_available = True\n",
        "except Exception as e:\n",
        "    print(f\"-> Lỗi kết nối OpenAI: {e}. Sẽ chuyển sang Kế hoạch B.\")\n",
        "    openai_available = False\n",
        "\n",
        "# 2. Định nghĩa hàm phân loại (ĐÃ SỬA LỖI GỌI HÀM)\n",
        "def classify_review_with_openai(review_text, category):\n",
        "    system_prompt = \"\"\"\n",
        "    You are an AI assistant for Google Maps. Your task is to analyze a review and classify it based on quality policies.\n",
        "    A review can have one or more violation labels. If no violations are found, classify it as \"clean\".\n",
        "\n",
        "    Possible Labels:\n",
        "    - \"ad\": Contains advertisements, promotions, or external links.\n",
        "    - \"irrelevant\": The content is not related to the given category.\n",
        "    - \"rant_no_visit\": A strong complaint that shows no evidence of a real visit.\n",
        "\n",
        "    You must respond ONLY with a valid JSON object containing a single key \"labels\" which is a list of strings.\n",
        "    For example: {\"labels\": [\"clean\"]} or {\"labels\": [\"ad\", \"irrelevant\"]}.\n",
        "    \"\"\"\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "    Please classify the following review for a place in the category \"{category}\".\n",
        "    Review Text: \"{review_text}\"\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            # SỬA LỖI Ở ĐÂY: Thêm 'model='\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            response_format={\"type\": \"json_object\"},\n",
        "            temperature=0.1\n",
        "        )\n",
        "        return json.loads(response.choices[0].message.content)\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"labels\": [f\"error_{str(e)}\"]}\n",
        "\n",
        "# 3. Chạy thử nghiệm nếu API khả dụng\n",
        "if openai_available:\n",
        "    print(\"\\nHàm phân loại bằng OpenAI đã sẵn sàng. Bắt đầu chạy thử nghiệm...\")\n",
        "    # Lấy 10 dòng cuối để test, bao gồm cả review quảng cáo giả\n",
        "    sample_df_openai = df.tail(10).copy()\n",
        "\n",
        "    openai_results = sample_df_openai.apply(\n",
        "        lambda row: classify_review_with_openai(row['text'], row['category']),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    sample_df_openai['openai_labels'] = [res.get('labels', ['error']) for res in openai_results]\n",
        "\n",
        "    print(\"\\n-> Kết quả phân loại đa nhãn từ OpenAI (GPT-3.5-Turbo):\")\n",
        "    print(sample_df_openai[['text', 'multilabels', 'openai_labels']])\n",
        "else:\n",
        "    print(\"\\nBỏ qua thử nghiệm OpenAI do kết nối không thành công.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWZ2FbNYEpUY",
        "outputId": "39b05fd7-90fc-48c8-d9a5-8d311a4e1abe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bắt đầu Kế hoạch A: Thử nghiệm với OpenAI API...\n",
            "-> Đã kết nối với API của OpenAI thành công!\n",
            "\n",
            "Hàm phân loại bằng OpenAI đã sẵn sàng. Bắt đầu chạy thử nghiệm...\n",
            "\n",
            "-> Kết quả phân loại đa nhãn từ OpenAI (GPT-3.5-Turbo):\n",
            "                                                    text   multilabels  \\\n",
            "25777  First time I tried their food will say it wasn...       [clean]   \n",
            "39737  I have been going here for years. All the staf...       [clean]   \n",
            "35036                                            Awesome       [clean]   \n",
            "1534                              Very helpful and nice.       [clean]   \n",
            "42774  A nice beach!  Fairly busy, arrive early to ge...  [irrelevant]   \n",
            "42827  A nice beach!  Fairly busy, arrive early to ge...  [irrelevant]   \n",
            "22297  Good food, better if you eat seafood.  Friendl...       [clean]   \n",
            "22299  Good food, better if you eat seafood.  Friendl...       [clean]   \n",
            "19157                 Food was good, staff was friendly.       [clean]   \n",
            "36516  Great place! visit www.mypromo.com for a 10% d...          [ad]   \n",
            "\n",
            "      openai_labels  \n",
            "25777       [clean]  \n",
            "39737       [clean]  \n",
            "35036  [irrelevant]  \n",
            "1534        [clean]  \n",
            "42774       [clean]  \n",
            "42827       [clean]  \n",
            "22297       [clean]  \n",
            "22299       [clean]  \n",
            "19157       [clean]  \n",
            "36516          [ad]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 8: MODEL DEVELOPMENT - KẾ HOẠCH B: FALLBACK VỚI SCIKIT-LEARN\n",
        "# ===================================================================\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "print(\"Thực hiện Kế hoạch B: Huấn luyện mô hình Scikit-learn.\")\n",
        "\n",
        "# 1. Chuẩn bị nhãn đơn để huấn luyện\n",
        "def create_single_label(row):\n",
        "    if 'ad' in row['multilabels']: return 'ad'\n",
        "    if 'rant_no_visit' in row['multilabels']: return 'rant_no_visit'\n",
        "    if 'irrelevant' in row['multilabels']: return 'irrelevant'\n",
        "    return 'clean'\n",
        "\n",
        "df['final_label'] = df.apply(create_single_label, axis=1)\n",
        "\n",
        "# 2. Chia dữ liệu\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['text_clean'], df['final_label'],\n",
        "    test_size=0.2, random_state=42, stratify=df['final_label']\n",
        ")\n",
        "\n",
        "# 3. Xây dựng và Huấn luyện Pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_features=2000, stop_words='english')),\n",
        "    ('clf', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
        "])\n",
        "pipeline.fit(X_train, y_train)\n",
        "print(\"-> Huấn luyện mô hình Scikit-learn hoàn tất!\")\n",
        "\n",
        "# 4. Dự đoán và lưu kết quả\n",
        "df['sklearn_classification'] = pipeline.predict(df['text_clean'])\n",
        "print(\"\\n-> Kết quả phân loại từ Scikit-learn:\")\n",
        "print(df[['text', 'final_label', 'sklearn_classification']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW_cGyMGErs1",
        "outputId": "35110e15-80d1-4327-ad67-37b9dcc0d262"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thực hiện Kế hoạch B: Huấn luyện mô hình Scikit-learn.\n",
            "-> Huấn luyện mô hình Scikit-learn hoàn tất!\n",
            "\n",
            "-> Kết quả phân loại từ Scikit-learn:\n",
            "                                                    text    final_label  \\\n",
            "648                     Great job have to have driver co          clean   \n",
            "44104                             Very easy to work with          clean   \n",
            "14627  Got the best haircut I've had in years by Marcus.          clean   \n",
            "23922  Great service- courteous and efficient.  And o...          clean   \n",
            "35287                                    low low prices!  rant_no_visit   \n",
            "\n",
            "      sklearn_classification  \n",
            "648                    clean  \n",
            "44104                  clean  \n",
            "14627                  clean  \n",
            "23922                  clean  \n",
            "35287          rant_no_visit  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 9: LƯU OUTPUT CUỐI CÙNG CHO DAY 3\n",
        "# ===================================================================\n",
        "# Lưu DataFrame đã được làm giàu với tất cả các feature và nhãn\n",
        "final_output_filename = 'final_augmented_reviews_for_day3.csv'\n",
        "df.to_csv(final_output_filename, index=False)\n",
        "\n",
        "print(f\"\\nĐÃ HOÀN THÀNH DAY 2!\")\n",
        "print(f\"Đã lưu thành công DataFrame cuối cùng vào file '{final_output_filename}'.\")\n",
        "print(\"File này chứa tất cả các đặc trưng và nhãn bạn cần cho Day 3 - Đánh giá mô hình.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpwSjEJcEugl",
        "outputId": "a7bcc2fe-63bf-465f-e463-142ea46f6a9d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ĐÃ HOÀN THÀNH DAY 2!\n",
            "Đã lưu thành công DataFrame cuối cùng vào file 'final_augmented_reviews_for_day3.csv'.\n",
            "File này chứa tất cả các đặc trưng và nhãn bạn cần cho Day 3 - Đánh giá mô hình.\n"
          ]
        }
      ]
    }
  ]
}