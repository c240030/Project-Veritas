{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ua6gSzdrJ-Kx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adde4c5c-071a-417e-aa91-3d51871007f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tải dữ liệu nâng cấp và tính điểm sentiment thành công!\n",
            "                                                text  sentiment_score  \\\n",
            "0  Lived here for 3 years and enjoyed it. Locatio...           0.8176   \n",
            "1  Lived here for 3 years and enjoyed it. Locatio...           0.8176   \n",
            "2  Nice complex and awesome staff.  Maintenance i...           0.9685   \n",
            "3  Nice complex and awesome staff.  Maintenance i...           0.9685   \n",
            "4  Good places for people to live my friend lives...           0.7269   \n",
            "\n",
            "                category  \n",
            "0  ['Apartment complex']  \n",
            "1  ['Apartment complex']  \n",
            "2  ['Apartment complex']  \n",
            "3  ['Apartment complex']  \n",
            "4  ['Apartment complex']  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "\n",
        "# Tải tài nguyên cần thiết cho VADER\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Tải dữ liệu đã được xử lý và gộp từ nguồn UCSD\n",
        "df = pd.read_csv('ucsd_delaware_reviews_combined.csv')\n",
        "\n",
        "# Khởi tạo VADER\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Tính toán điểm sentiment (đảm bảo cột 'text' không có giá trị NaN)\n",
        "df.dropna(subset=['text'], inplace=True)\n",
        "df['sentiment_score'] = df['text'].apply(lambda text: analyzer.polarity_scores(str(text))['compound'])\n",
        "\n",
        "print(\"Tải dữ liệu nâng cấp và tính điểm sentiment thành công!\")\n",
        "print(df[['text', 'sentiment_score', 'category']].head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Đặc trưng Metadata ---\n",
        "# Độ dài review (số ký tự)\n",
        "df['review_length'] = df['text'].str.len()\n",
        "\n",
        "# Đếm số review của mỗi user\n",
        "# .transform('count') sẽ gán số đếm cho mỗi dòng của user đó\n",
        "df['user_review_count'] = df.groupby('user_id')['user_id'].transform('count')\n",
        "\n",
        "# Độ chênh lệch giữa rating của review và rating trung bình của địa điểm\n",
        "# fillna(0) để xử lý các trường hợp không có avg_rating\n",
        "df['rating_deviation'] = (df['rating'] - df['avg_rating']).fillna(0)\n",
        "\n",
        "\n",
        "# --- 2. Suy luận Tín hiệu \"Đã ghé thăm\" ---\n",
        "# Các từ khóa cho thấy người dùng đã thực sự đến địa điểm\n",
        "visit_keywords = [\n",
        "    'visited', 'went to', 'ate here', 'dined here', 'was there',\n",
        "    'stayed at', 'my visit', 'our visit', 'ordered', 'tried the'\n",
        "]\n",
        "# Tạo cờ (flag) nếu text chứa bất kỳ từ khóa nào trong danh sách trên\n",
        "df['has_visit_keyword'] = df['text'].str.contains('|'.join(visit_keywords), case=False, na=False)\n",
        "\n",
        "print(\"Tạo các đặc trưng mới thành công!\")\n",
        "# Hiển thị các cột mới để kiểm tra\n",
        "print(df[['user_name', 'review_length', 'user_review_count', 'rating_deviation', 'has_visit_keyword']].head())"
      ],
      "metadata": {
        "id": "kcN5O7JLKMJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0093e01-b611-4229-c3be-fe018d6dcf6b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tạo các đặc trưng mới thành công!\n",
            "        user_name  review_length  user_review_count  rating_deviation  \\\n",
            "0  Heather Carper            112                  4               0.5   \n",
            "1  Heather Carper            112                  4               0.5   \n",
            "2  STACY CLAVETTE            283                  5               0.5   \n",
            "3  STACY CLAVETTE            283                  5               0.5   \n",
            "4       Zion Hood             74                  5               0.5   \n",
            "\n",
            "   has_visit_keyword  \n",
            "0              False  \n",
            "1              False  \n",
            "2              False  \n",
            "3              False  \n",
            "4              False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_violations_rules(row):\n",
        "    flags = {}\n",
        "\n",
        "    # Chính sách 1: Rant không ghé thăm\n",
        "    # Điều kiện: sentiment rất tiêu cực VÀ không có từ khóa ghé thăm\n",
        "    is_rant_no_visit = row['sentiment_score'] < -0.5 and not row['has_visit_keyword']\n",
        "    flags['is_rant_without_visit'] = is_rant_no_visit\n",
        "\n",
        "    # Chính sách 2: Nội dung không liên quan (dựa trên quy tắc đơn giản)\n",
        "    # Điều kiện: Review quá ngắn (có thể là spam hoặc không có giá trị)\n",
        "    is_irrelevant = row['review_length'] < 20\n",
        "    flags['is_irrelevant'] = is_irrelevant\n",
        "\n",
        "    # Thêm cờ 'is_clean' nếu không có vi phạm nào bị phát hiện\n",
        "    flags['is_clean_by_rules'] = not any([is_rant_no_visit, is_irrelevant])\n",
        "\n",
        "    return pd.Series(flags)\n",
        "\n",
        "# Áp dụng hàm cho toàn bộ DataFrame\n",
        "rule_based_flags = df.apply(detect_violations_rules, axis=1)\n",
        "df = pd.concat([df, rule_based_flags], axis=1)\n",
        "\n",
        "print(\"Đã gắn cờ vi phạm dựa trên luật thành công!\")\n",
        "# Kiểm tra các review bị gắn cờ là \"rant không ghé thăm\"\n",
        "print(\"\\nCác review có khả năng là 'Rant không ghé thăm':\")\n",
        "print(df[df['is_rant_without_visit'] == True][['text', 'sentiment_score', 'has_visit_keyword']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqKRd0UFKqTR",
        "outputId": "497bb076-29f9-4623-c62d-432abacaef80"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã gắn cờ vi phạm dựa trên luật thành công!\n",
            "\n",
            "Các review có khả năng là 'Rant không ghé thăm':\n",
            "                                                 text  sentiment_score  \\\n",
            "30  I love this place I have severe fibromyalgia m...          -0.5568   \n",
            "31  I love this place I have severe fibromyalgia m...          -0.5568   \n",
            "42  I run a law firm. They deposit client trust mo...          -0.8070   \n",
            "43  I run a law firm. They deposit client trust mo...          -0.8070   \n",
            "84  Took my Miter saw in to replace the handle bec...          -0.5990   \n",
            "\n",
            "    has_visit_keyword  \n",
            "30              False  \n",
            "31              False  \n",
            "42              False  \n",
            "43              False  \n",
            "84              False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import huggingface_hub\n",
        "\n",
        "try:\n",
        "    hf_token = userdata.get('HF_TOKEN')\n",
        "    huggingface_hub.login(token=hf_token)\n",
        "    print(\"Đăng nhập Hugging Face thành công!\")\n",
        "except Exception as e:\n",
        "    print(\"Lỗi! Hãy chắc chắn bạn đã lưu 'HF_TOKEN' trong Colab Secrets.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kGXUoOoKuP0",
        "outputId": "582525b2-ecc2-49af-f92e-544e2cdb4895"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đăng nhập Hugging Face thành công!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PHƯƠ-NG ÁN B: FALLBACK SỬ DỤNG SCIKIT-LEARN (ĐÃ SỬA LỖI) ---\n",
        "print(\"API của LLM không khả dụng, chuyển sang Kế hoạch B: Dùng Scikit-learn.\")\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split # Import thêm để chia dữ liệu\n",
        "\n",
        "# 1. Chuẩn bị dữ liệu huấn luyện\n",
        "def create_label(row):\n",
        "    if row['is_rant_without_visit']:\n",
        "        return 'rant_no_visit'\n",
        "    if row['is_irrelevant']:\n",
        "        return 'irrelevant'\n",
        "    return 'clean'\n",
        "\n",
        "df['rule_based_label'] = df.apply(create_label, axis=1)\n",
        "\n",
        "# Xử lý các giá trị NaN tiềm ẩn trong cột text_clean ngay từ đầu\n",
        "df['text_clean'] = df['text_clean'].fillna('')\n",
        "\n",
        "# Chia dữ liệu thành tập huấn luyện và tập kiểm thử (để đánh giá trong Day 3)\n",
        "# Chúng ta sẽ huấn luyện mô hình trên 80% dữ liệu\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['text_clean'],\n",
        "    df['rule_based_label'],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['rule_based_label'] # Giữ tỷ lệ các nhãn\n",
        ")\n",
        "\n",
        "# 2. Xây dựng Pipeline\n",
        "text_clf_pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_features=1000, stop_words='english')),\n",
        "    ('clf', LogisticRegression(max_iter=1000, class_weight='balanced')),\n",
        "])\n",
        "\n",
        "# 3. Huấn luyện mô hình\n",
        "print(\"\\nĐang huấn luyện mô hình Logistic Regression...\")\n",
        "text_clf_pipeline.fit(X_train, y_train)\n",
        "print(\"Huấn luyện hoàn tất!\")\n",
        "\n",
        "# 4. Đưa ra dự đoán trên toàn bộ dữ liệu (bây giờ sẽ không lỗi)\n",
        "df['sklearn_classification'] = text_clf_pipeline.predict(df['text_clean'])\n",
        "\n",
        "# 5. Hiển thị kết quả\n",
        "print(\"\\nKết quả phân loại bằng Scikit-learn (10 dòng đầu):\")\n",
        "print(df[['text', 'rule_based_label', 'sklearn_classification']].head(10))\n",
        "\n",
        "# Kiểm tra xem nó có phát hiện đúng các trường hợp \"rant\" không\n",
        "print(\"\\nKiểm tra các trường hợp 'rant' do model dự đoán:\")\n",
        "print(df[df['sklearn_classification'] == 'rant_no_visit'][['text', 'sentiment_score']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhWjw1MQKyq8",
        "outputId": "56ae9ee6-7b9d-4a13-8815-48759533c260"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API của LLM không khả dụng, chuyển sang Kế hoạch B: Dùng Scikit-learn.\n",
            "\n",
            "Đang huấn luyện mô hình Logistic Regression...\n",
            "Huấn luyện hoàn tất!\n",
            "\n",
            "Kết quả phân loại bằng Scikit-learn (10 dòng đầu):\n",
            "                                                text rule_based_label  \\\n",
            "0  Lived here for 3 years and enjoyed it. Locatio...            clean   \n",
            "1  Lived here for 3 years and enjoyed it. Locatio...            clean   \n",
            "2  Nice complex and awesome staff.  Maintenance i...            clean   \n",
            "3  Nice complex and awesome staff.  Maintenance i...            clean   \n",
            "4  Good places for people to live my friend lives...            clean   \n",
            "5  Good places for people to live my friend lives...            clean   \n",
            "6                                      great layout.       irrelevant   \n",
            "7                                      great layout.       irrelevant   \n",
            "8  Positives: Elevator, dog park and maintenance....            clean   \n",
            "9  Positives: Elevator, dog park and maintenance....            clean   \n",
            "\n",
            "  sklearn_classification  \n",
            "0                  clean  \n",
            "1                  clean  \n",
            "2                  clean  \n",
            "3                  clean  \n",
            "4                  clean  \n",
            "5                  clean  \n",
            "6             irrelevant  \n",
            "7             irrelevant  \n",
            "8                  clean  \n",
            "9                  clean  \n",
            "\n",
            "Kiểm tra các trường hợp 'rant' do model dự đoán:\n",
            "                                                 text  sentiment_score\n",
            "18           Quality service! Won't go anywhere else.           0.0000\n",
            "19           Quality service! Won't go anywhere else.           0.0000\n",
            "30  I love this place I have severe fibromyalgia m...          -0.5568\n",
            "31  I love this place I have severe fibromyalgia m...          -0.5568\n",
            "42  I run a law firm. They deposit client trust mo...          -0.8070\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To be done:\n",
        "# Keyword extraction, topic modeling (LDA)\n",
        "# timestamp delta\n",
        "# For ads (regex for URLs/promos)\n",
        "# Multi-label classification\n",
        "# Prompt Engineering\n",
        "# Use Hugging Face Inference"
      ],
      "metadata": {
        "id": "WDizvKJ1iLOm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeQjx_BBiMVn",
        "outputId": "a2ca0dc3-856a-402d-dafd-cfbe20eab52e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "\n",
        "# Khởi tạo TF-IDF Vectorizer\n",
        "# Chúng ta sẽ chỉ xem xét 2000 từ phổ biến nhất để tăng tốc\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=2000, stop_words='english')\n",
        "\n",
        "# Fit trên toàn bộ cột text_clean để học từ vựng và trọng số IDF\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df['text_clean'].fillna(''))\n",
        "# Lấy danh sách các từ (features)\n",
        "feature_names = np.array(tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "def extract_top_keywords(doc, top_n=5):\n",
        "    \"\"\"Trích xuất top N từ khóa từ một văn bản dựa trên TF-IDF đã fit.\"\"\"\n",
        "    # Transform chỉ văn bản này\n",
        "    tfidf_vector = tfidf_vectorizer.transform([doc])\n",
        "    # Sắp xếp các chỉ số của các từ theo điểm TF-IDF\n",
        "    sorted_indices = np.argsort(tfidf_vector.toarray()).flatten()[::-1]\n",
        "    # Lấy ra top N từ khóa\n",
        "    top_keywords = feature_names[sorted_indices[:top_n]]\n",
        "    return ', '.join(top_keywords)\n",
        "\n",
        "# Áp dụng hàm này để tạo một cột mới\n",
        "# Lưu ý: Bước này có thể hơi chậm nếu dữ liệu lớn\n",
        "df['keywords'] = df['text_clean'].fillna('').apply(extract_top_keywords)\n",
        "\n",
        "print(\"Đã trích xuất từ khóa bằng TF-IDF:\")\n",
        "print(df[['text', 'keywords']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YqnFJAWij8Q",
        "outputId": "c2f50d06-cb35-46bc-8248-b1f50f7c48d2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã trích xuất từ khóa bằng TF-IDF:\n",
            "                                                text  \\\n",
            "0  Lived here for 3 years and enjoyed it. Locatio...   \n",
            "1  Lived here for 3 years and enjoyed it. Locatio...   \n",
            "2  Nice complex and awesome staff.  Maintenance i...   \n",
            "3  Nice complex and awesome staff.  Maintenance i...   \n",
            "4  Good places for people to live my friend lives...   \n",
            "\n",
            "                                           keywords  \n",
            "0    convenience, views, apartments, lived, enjoyed  \n",
            "1    convenience, views, apartments, lived, enjoyed  \n",
            "2  close, complex, apartments, maintenance, located  \n",
            "3  close, complex, apartments, maintenance, located  \n",
            "4                 awsome, lives, says, friend, live  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "\n",
        "# Token hóa văn bản (tách thành các từ)\n",
        "tokenized_data = [text.split() for text in df['text_clean'].fillna('')]\n",
        "\n",
        "# Tạo từ điển và kho văn bản (corpus)\n",
        "dictionary = corpora.Dictionary(tokenized_data)\n",
        "# Lọc các từ quá hiếm hoặc quá phổ biến\n",
        "dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
        "corpus = [dictionary.doc2bow(text) for text in tokenized_data]\n",
        "\n",
        "print(\"Đã chuẩn bị dữ liệu cho LDA.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSnCG-hbjSVg",
        "outputId": "19f91e9d-bd31-4193-f971-ab36365b3eef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã chuẩn bị dữ liệu cho LDA.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Huấn luyện mô hình LDA để tìm ra 5 chủ đề\n",
        "# Bước này cũng có thể mất vài phút\n",
        "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, passes=10, random_state=42)\n",
        "\n",
        "print(\"Đã huấn luyện xong mô hình LDA. Dưới đây là 5 chủ đề chính:\")\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print(f'Topic: {idx} \\nWords: {topic}\\n')\n",
        "\n",
        "# Gán chủ đề chính cho mỗi review\n",
        "def get_dominant_topic(doc):\n",
        "    bow = dictionary.doc2bow(doc.split())\n",
        "    topics = lda_model.get_document_topics(bow)\n",
        "    # Chọn chủ đề có xác suất cao nhất\n",
        "    dominant_topic = sorted(topics, key=lambda x: x[1], reverse=True)[0][0]\n",
        "    return dominant_topic\n",
        "\n",
        "df['topic'] = df['text_clean'].fillna('').apply(get_dominant_topic)\n",
        "\n",
        "print(\"\\nĐã gán chủ đề cho mỗi review:\")\n",
        "print(df[['text', 'topic']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZj2Sx12jWPN",
        "outputId": "7c014879-ae9d-4737-a114-9ca46813d660"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã huấn luyện xong mô hình LDA. Dưới đây là 5 chủ đề chính:\n",
            "Topic: 0 \n",
            "Words: 0.048*\"the\" + 0.035*\"to\" + 0.024*\"you\" + 0.023*\"i\" + 0.023*\"they\" + 0.023*\"and\" + 0.023*\"a\" + 0.019*\"is\" + 0.018*\"have\" + 0.014*\"of\"\n",
            "\n",
            "Topic: 1 \n",
            "Words: 0.051*\"a\" + 0.034*\"to\" + 0.031*\"of\" + 0.031*\"place\" + 0.030*\"great\" + 0.029*\"for\" + 0.025*\"and\" + 0.025*\"nice\" + 0.016*\"good\" + 0.013*\"very\"\n",
            "\n",
            "Topic: 2 \n",
            "Words: 0.093*\"the\" + 0.039*\"and\" + 0.032*\"was\" + 0.029*\"food\" + 0.024*\"is\" + 0.021*\"it\" + 0.019*\"best\" + 0.017*\"good\" + 0.015*\"love\" + 0.014*\"a\"\n",
            "\n",
            "Topic: 3 \n",
            "Words: 0.097*\"and\" + 0.090*\"great\" + 0.061*\"very\" + 0.055*\"service\" + 0.044*\"friendly\" + 0.043*\"staff\" + 0.042*\"good\" + 0.026*\"food\" + 0.021*\"helpful\" + 0.021*\"always\"\n",
            "\n",
            "Topic: 4 \n",
            "Words: 0.046*\"i\" + 0.041*\"and\" + 0.038*\"the\" + 0.037*\"was\" + 0.033*\"to\" + 0.029*\"my\" + 0.025*\"a\" + 0.016*\"me\" + 0.016*\"for\" + 0.014*\"it\"\n",
            "\n",
            "\n",
            "Đã gán chủ đề cho mỗi review:\n",
            "                                                text  topic\n",
            "0  Lived here for 3 years and enjoyed it. Locatio...      0\n",
            "1  Lived here for 3 years and enjoyed it. Locatio...      0\n",
            "2  Nice complex and awesome staff.  Maintenance i...      0\n",
            "3  Nice complex and awesome staff.  Maintenance i...      0\n",
            "4  Good places for people to live my friend lives...      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chuyển đổi cột 'time' (miligiây) sang định dạng datetime\n",
        "df['datetime'] = pd.to_datetime(df['time'], unit='ms')\n",
        "\n",
        "# Sắp xếp DataFrame theo user và thời gian\n",
        "df = df.sort_values(by=['user_id', 'datetime'])\n",
        "\n",
        "# Tính toán sự khác biệt về thời gian (tính bằng giây) so với review trước đó của cùng một user\n",
        "df['time_delta_seconds'] = df.groupby('user_id')['datetime'].diff().dt.total_seconds().fillna(0)\n",
        "\n",
        "print(\"Đã tính toán chênh lệch thời gian giữa các review của cùng user:\")\n",
        "print(df[['user_name', 'datetime', 'time_delta_seconds']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0OlwvSujY_k",
        "outputId": "ba871ae3-f9aa-4bd9-b905-ccb76b0b9f52"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã tính toán chênh lệch thời gian giữa các review của cùng user:\n",
            "          user_name                datetime  time_delta_seconds\n",
            "648     Ronald Keys 2018-03-01 15:56:48.891        0.000000e+00\n",
            "44104  Don Kelleher 2020-05-21 21:43:37.803        0.000000e+00\n",
            "14627   Tom Carroll 2020-02-08 01:04:21.369        0.000000e+00\n",
            "23922   Tom Carroll 2020-10-11 14:24:50.518        2.130243e+07\n",
            "35287  Jeff Peacock 2017-07-23 02:04:50.769        0.000000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo một vài review giả có chứa URL để kiểm tra\n",
        "promo_text_1 = \"Great place! visit www.mypromo.com for a 10% discount!\"\n",
        "promo_text_2 = \"I loved it, check out my blog at http://myblog.net\"\n",
        "df.loc[len(df)] = df.iloc[0] # Copy một dòng để làm mẫu\n",
        "df.loc[len(df)-1, 'text'] = promo_text_1\n",
        "df.loc[len(df)] = df.iloc[1]\n",
        "df.loc[len(df)-1, 'text'] = promo_text_2\n",
        "\n",
        "# Định nghĩa lại pattern để bắt URL\n",
        "url_pattern = r'(https|http|www)[^\\s]+'\n",
        "df['has_url'] = df['text'].str.contains(url_pattern, case=False, na=False)\n",
        "\n",
        "print(f\"Số review có URL sau khi thêm mẫu: {df['has_url'].sum()}\")\n",
        "print(\"Các review chứa URL:\")\n",
        "print(df[df['has_url']][['text', 'has_url']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRT_ovMajbkm",
        "outputId": "0fff8b8a-0e99-4d96-ab1c-80d5bb79ede7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4177106586.py:11: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  df['has_url'] = df['text'].str.contains(url_pattern, case=False, na=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Số review có URL sau khi thêm mẫu: 7\n",
            "Các review chứa URL:\n",
            "                                                    text  has_url\n",
            "9783   Incredibly delicious!!\\nAs always.\\nLuv the su...     True\n",
            "31808  Very disorganized staff unfriendly and unhelpf...     True\n",
            "58287  I loved it, check out my blog at http://myblog...     True\n",
            "27067  I live by this place. I don't eat Chinese but ...     True\n",
            "23844  (Translated by Google) Awwweeeessssooooomeeee ...     True\n",
            "52771  (Translated by Google) Slowwwww at the pharmac...     True\n",
            "37895  Time well spent and well worth it.\\nEvery wher...     True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sửa lại hàm để tạo ra nhiều cột nhãn (multi-label)\n",
        "def create_multilabels(row):\n",
        "    labels = []\n",
        "    # Chính sách 1: Rant không ghé thăm\n",
        "    if row['sentiment_score'] < -0.5 and not row['has_visit_keyword']:\n",
        "        labels.append('rant_no_visit')\n",
        "    # Chính sách 2: Quảng cáo\n",
        "    if row['has_url']:\n",
        "        labels.append('ad')\n",
        "    # Chính sách 3: Không liên quan (VD: chủ đề 4 là chủ đề lạ)\n",
        "    # Giả sử sau khi xem các chủ đề ở trên, bạn thấy topic 4 là không liên quan\n",
        "    if row['topic'] == 4: # Thay số 4 bằng chỉ số topic bạn cho là không liên quan\n",
        "        labels.append('irrelevant')\n",
        "\n",
        "    # Nếu không có nhãn nào, nó là 'clean'\n",
        "    if not labels:\n",
        "        labels.append('clean')\n",
        "\n",
        "    return labels\n",
        "\n",
        "df['multilabels'] = df.apply(create_multilabels, axis=1)\n",
        "\n",
        "print(\"\\nĐã tạo các nhãn đa trị (multi-label):\")\n",
        "print(df[['text', 'multilabels']].tail()) # Xem các review quảng cáo vừa thêm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0MskKACjfPn",
        "outputId": "593313d8-a37e-4b0e-f248-022ee110f2c8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Đã tạo các nhãn đa trị (multi-label):\n",
            "                                                    text multilabels\n",
            "42827  A nice beach!  Fairly busy, arrive early to ge...     [clean]\n",
            "22297  Good food, better if you eat seafood.  Friendl...     [clean]\n",
            "22299  Good food, better if you eat seafood.  Friendl...     [clean]\n",
            "19157                 Food was good, staff was friendly.     [clean]\n",
            "36516  Always great meats, great prices,  great servi...     [clean]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Đảm bảo bạn đã login\n",
        "# huggingface_hub.login(token=userdata.get('HF_TOKEN'))\n",
        "client = InferenceClient()\n",
        "\n",
        "# Prompt đã được cải tiến để xử lý multi-label và yêu cầu output JSON\n",
        "def classify_review_llm_multilabel(review_text, category):\n",
        "    prompt = f\"\"\"\n",
        "    As an AI assistant for Google Maps, analyze the following review for a place in the category \"{category}\".\n",
        "    A review can have one or more of the following violation labels. If no violations are found, classify it as \"clean\".\n",
        "\n",
        "    Possible Labels:\n",
        "    - \"ad\": Contains advertisements, promotions, or external links.\n",
        "    - \"irrelevant\": The content is not related to the given category.\n",
        "    - \"rant_no_visit\": A strong complaint that shows no evidence of a real visit.\n",
        "\n",
        "    Provide your answer ONLY in a valid JSON format with a single key \"labels\" which is a list of strings.\n",
        "    For example: {{\"labels\": [\"clean\"]}} or {{\"labels\": [\"ad\", \"irrelevant\"]}}.\n",
        "\n",
        "    Review Text:\n",
        "    \"{review_text}\"\n",
        "\n",
        "    JSON Output:\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.text_generation(prompt, model=\"mistralai/Mistral-7B-Instruct-v0.2\", max_new_tokens=100, temperature=0.1)\n",
        "\n",
        "        json_part = response[response.find('{'):response.rfind('}')+1]\n",
        "        if json_part:\n",
        "            return json.loads(json_part)\n",
        "        else:\n",
        "            return {\"labels\": [\"error_parsing\"]}\n",
        "    except Exception as e:\n",
        "        if \"is currently loading\" in str(e):\n",
        "            print(\"Model is loading, retrying...\")\n",
        "            time.sleep(15)\n",
        "            return classify_review_llm_multilabel(review_text, category)\n",
        "        return {\"labels\": [f\"error_{str(e)}\"]}\n",
        "\n",
        "# Thử nghiệm trên một mẫu nhỏ, bao gồm cả các review quảng cáo bạn vừa tạo\n",
        "sample_df_llm = df.tail(10).copy() # Lấy 10 review cuối, bao gồm cả review giả\n",
        "\n",
        "llm_results = sample_df_llm.apply(\n",
        "    lambda row: classify_review_llm_multilabel(row['text'], row['category']),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "sample_df_llm['llm_labels'] = [res.get('labels', ['error']) for res in llm_results]\n",
        "\n",
        "print(\"\\nKết quả phân loại đa nhãn từ LLM (Mistral):\")\n",
        "print(sample_df_llm[['text', 'multilabels', 'llm_labels']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csR-Hzk_jkXl",
        "outputId": "7dd3d000-c473-4b22-b782-fa2948e0c920"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Kết quả phân loại đa nhãn từ LLM (Mistral):\n",
            "                                                    text multilabels  \\\n",
            "25777  First time I tried their food will say it wasn...     [clean]   \n",
            "39737  I have been going here for years. All the staf...     [clean]   \n",
            "35036                                            Awesome     [clean]   \n",
            "1534                              Very helpful and nice.     [clean]   \n",
            "42774  A nice beach!  Fairly busy, arrive early to ge...     [clean]   \n",
            "42827  A nice beach!  Fairly busy, arrive early to ge...     [clean]   \n",
            "22297  Good food, better if you eat seafood.  Friendl...     [clean]   \n",
            "22299  Good food, better if you eat seafood.  Friendl...     [clean]   \n",
            "19157                 Food was good, staff was friendly.     [clean]   \n",
            "36516  Always great meats, great prices,  great servi...     [clean]   \n",
            "\n",
            "                                              llm_labels  \n",
            "25777  [error_Model mistralai/Mistral-7B-Instruct-v0....  \n",
            "39737  [error_Model mistralai/Mistral-7B-Instruct-v0....  \n",
            "35036  [error_Model mistralai/Mistral-7B-Instruct-v0....  \n",
            "1534   [error_Model mistralai/Mistral-7B-Instruct-v0....  \n",
            "42774  [error_Model mistralai/Mistral-7B-Instruct-v0....  \n",
            "42827  [error_Model mistralai/Mistral-7B-Instruct-v0....  \n",
            "22297  [error_Model mistralai/Mistral-7B-Instruct-v0....  \n",
            "22299  [error_Model mistralai/Mistral-7B-Instruct-v0....  \n",
            "19157  [error_Model mistralai/Mistral-7B-Instruct-v0....  \n",
            "36516  [error_Model mistralai/Mistral-7B-Instruct-v0....  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lưu DataFrame đã được làm giàu với tất cả các feature và label\n",
        "final_output_filename = 'final_augmented_reviews_for_day3.csv'\n",
        "df.to_csv(final_output_filename, index=False)\n",
        "\n",
        "print(f\"Đã lưu thành công DataFrame cuối cùng vào file '{final_output_filename}'.\")\n",
        "print(\"Đây là đầu vào cần cho Day 3.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rx9v-6Mrn06Z",
        "outputId": "3aa3a290-d3d4-4a03-9c74-fca3eb192f70"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã lưu thành công DataFrame cuối cùng vào file 'final_augmented_reviews_for_day3.csv'.\n",
            "Đây là đầu vào cần cho Day 3.\n"
          ]
        }
      ]
    }
  ]
}